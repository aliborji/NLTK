{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 text and words\n",
    "##1.3 searching text\n",
    "\n",
    "# see words in context\n",
    "#text1.concordance(\"monstrous\")\n",
    "\n",
    "#similar in range of context\n",
    "# text1.similar(\"monstrous\") \n",
    "\n",
    "#examine just the context that are shared by two or more words\n",
    "# text2.common_contexts(['monstrous','very'])\n",
    "\n",
    "#display the position information of a word, detect a particular word occurs in a text, and to display some words that appear in the same context\n",
    "# text4.dispersion_plot(['citizens','democracy','freedom','duties','America'])\n",
    "\n",
    "# generate some random text in the various styles\n",
    "# does not exist in NLTK3.0 but will be reinstated in a subsequent version\n",
    "#text1.generate() \n",
    "\n",
    "##1.4 counting vocabulary\n",
    "# count word tokens\n",
    "# len(text1)\n",
    "\n",
    "#sorted list\n",
    "# sorted(set(text3)) \n",
    "#sorted size of voc\n",
    "# count word types\n",
    "# len(set(text3))\n",
    "\n",
    "#calculate a measure of lexical richness\n",
    "from __future__ import division\n",
    "len(set(text3))/len(text3)\n",
    "\n",
    "#counts how often a word occurs\n",
    "text3.count('smote')\n",
    "#(percentage)\n",
    "100*text4.count('a')/len(text4)\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    return len(set(text))/len(text)\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100*count/total\n",
    "\n",
    "\n",
    "lexical_diversity(text3)\n",
    "lexical_diversity(text5)\n",
    "\n",
    "percentage(text4.count('a'), len(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-b8f1950d30c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'First'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "#2 texts as lists of words\n",
    "#lists\n",
    "# sent1 = ['Call', 'me', 'Ishmael', '.']\n",
    "# lexical_diversity(sent1)\n",
    "# sent2\n",
    "# sent3\n",
    "# sent4+sent1\n",
    "# sent1\n",
    "\n",
    "#indexing lists\n",
    "text4[173]\n",
    "text4.index('awaken')\n",
    "\n",
    "text5[16715:16735]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal\n",
      "Government; General Government; American people; Vice President; Old\n",
      "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;\n",
      "God bless; every citizen; Indian tribes; public debt; one another;\n",
      "foreign nations; political parties\n",
      "would like; medium build; social drinker; quiet nights; non smoker;\n",
      "long term; age open; Would like; easy going; financially secure; fun\n",
      "times; similar interests; Age open; weekends away; poss rship; well\n",
      "presented; never married; single mum; permanent relationship; slim\n",
      "build\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19255882431878046"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 Simple statistics\n",
    "#3.1 Frequency Distributions\n",
    "fdist1 = FreqDist(text1)\n",
    "#print fdist1\n",
    "# 50 most frequent words\n",
    "#print fdist1.most_common(50)\n",
    "fdist1['whale']\n",
    "\n",
    "# generate a cumulative frequency plot\n",
    "#fdist1.plot(50, cumulative=True)\n",
    "\n",
    "#3.2 Fine-grained Selection of Words\n",
    "V = set(text1)\n",
    "long_words = [w for w in V if len(w)>15]\n",
    "sorted(long_words)\n",
    "\n",
    "fdist5 = FreqDist(text5)\n",
    "sorted(w for w in set(text5) if len(w)>7 and fdist5[w]>7)\n",
    "\n",
    "#3.3 Collocations and Bigrams\n",
    "from nltk import bigrams\n",
    "list(bigrams(['more','is','said','than','done']))\n",
    "\n",
    "#find bigrams that occur more often than we would expect\n",
    "text4.collocations()\n",
    "text8.collocations()\n",
    "\n",
    "#3.4 COunting other things\n",
    "[len(w) for w in text1]\n",
    "\n",
    "#distributions of word length\n",
    "fdist = FreqDist(len(w) for w in text1)\n",
    "#print fdist\n",
    "fdist\n",
    "\n",
    "# List the n most common elements and their counts from the most common to the least.\n",
    "fdist.most_common()\n",
    "#the most frequent word length\n",
    "fdist.max()\n",
    "#the word of length 3\n",
    "fdist[3]\n",
    "#the frequency of word of lenth 3\n",
    "fdist.freq(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#4 Making Decisions and Taking Control\n",
    "#4.1 Conditionals\n",
    "#s.startwith(t)\n",
    "#s.endswith(t)\n",
    "#s.islower(), isupper(), isalpha(), isalnum(), isdigit(), istitle()\n",
    "\n",
    "#4.2 Operating on every element\n",
    "# [w.upper() for w in text1]\n",
    "\n",
    "#4.3 Nested code blocks\n",
    "#if..\n",
    "#4.4 Looping with conditions\n",
    "# for..\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5 Automatic Natural Language Understanding\n",
    "#5.1 Word Sense Disambiguation\n",
    "#5.2 Pronoun Resolution (anaphora resolution, semantic role labeling)\n",
    "#5.3 Generating language output: question answering, machine translation\n",
    "#5.4 Machine Translation (text alighment)\n",
    "#5.5 Spoken Dialog Systems\n",
    "#5.6 Textual Entailment(Recognizing Textual Entailment, RTE)\n",
    "#5.7 Limitation fo NLPf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
